{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":98188,"databundleVersionId":12673416,"sourceType":"competition"}],"dockerImageVersionId":31041,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\nbase_path = '/kaggle/input/mtcaic3'\ntrain_df = pd.read_csv(f'{base_path}/train.csv')\nval_df = pd.read_csv(f'{base_path}/validation.csv')\n\nssvep_df = pd.concat([\n    train_df[train_df['task'] == 'SSVEP'],\n    val_df[val_df['task'] == 'SSVEP']\n], ignore_index=True)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-30T19:42:03.078720Z","iopub.execute_input":"2025-06-30T19:42:03.079007Z","iopub.status.idle":"2025-06-30T19:42:05.224215Z","shell.execute_reply.started":"2025-06-30T19:42:03.078974Z","shell.execute_reply":"2025-06-30T19:42:05.223275Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"label_map = {'Left': 0, 'Right': 1, 'Forward': 2, 'Backward': 3}\nssvep_df['label'] = ssvep_df['label'].map(label_map)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T19:42:13.010451Z","iopub.execute_input":"2025-06-30T19:42:13.010768Z","iopub.status.idle":"2025-06-30T19:42:13.019334Z","shell.execute_reply.started":"2025-06-30T19:42:13.010742Z","shell.execute_reply":"2025-06-30T19:42:13.018406Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport os\n\ndef load_ssvep_trial(row, dataset='train', base_path='./mtc-aic3_dataset'):\n    subject_id = row['subject_id']\n    trial_session = row['trial_session']\n    trial_num = int(row['trial'])\n    eeg_path = f\"{base_path}/SSVEP/{dataset}/{subject_id}/{trial_session}/EEGdata.csv\"\n    \n    eeg_data = pd.read_csv(eeg_path)\n    samples_per_trial = 1750\n    start_idx = (trial_num - 1) * samples_per_trial\n    end_idx = start_idx + samples_per_trial\n    trial_segment = eeg_data.iloc[start_idx:end_idx]\n    \n    selected_channels = ['OZ', 'PZ', 'CZ', 'PO8']\n    return trial_segment[selected_channels].values.T.astype(np.float32)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T19:42:17.911732Z","iopub.execute_input":"2025-06-30T19:42:17.912117Z","iopub.status.idle":"2025-06-30T19:42:17.919831Z","shell.execute_reply.started":"2025-06-30T19:42:17.912088Z","shell.execute_reply":"2025-06-30T19:42:17.919066Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def load_trial(row, dataset_type):\n    eeg_path = f\"{base_path}/SSVEP/{dataset_type}/{row['subject_id']}/{row['trial_session']}/EEGdata.csv\"\n    eeg = pd.read_csv(eeg_path)\n    trial_num = int(row['trial'])\n    start = (trial_num - 1) * 1750\n    end = trial_num * 1750\n    selected_channels = ['OZ', 'PZ', 'CZ', 'PO8']\n    return eeg[selected_channels].iloc[start:end].values.T.astype(np.float32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T19:42:24.781786Z","iopub.execute_input":"2025-06-30T19:42:24.782083Z","iopub.status.idle":"2025-06-30T19:42:24.787772Z","shell.execute_reply.started":"2025-06-30T19:42:24.782034Z","shell.execute_reply":"2025-06-30T19:42:24.786819Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def extract_features(signal):\n    features = []\n    for ch in signal:\n        # Time-domain\n        features.extend([\n            np.mean(ch), np.std(ch), np.min(ch), np.max(ch),\n            np.sum(ch**2),  # Energy\n            np.sqrt(np.mean(ch**2)),  # RMS\n        ])\n        # Frequency-domain\n        fft = np.fft.rfft(ch)\n        power = np.abs(fft)**2\n        features.append(np.sum(power[7:10]))   # 7–10 Hz (Forward)\n        features.append(np.sum(power[10:13]))  # 10–13 Hz (Left/Right)\n    return np.array(features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T19:42:29.670125Z","iopub.execute_input":"2025-06-30T19:42:29.670910Z","iopub.status.idle":"2025-06-30T19:42:29.676447Z","shell.execute_reply.started":"2025-06-30T19:42:29.670881Z","shell.execute_reply":"2025-06-30T19:42:29.675519Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"X = []\ny = []\n\nfor _, row in ssvep_df.iterrows():\n    dataset_type = 'train' if row['id'] <= 4800 else 'validation'\n    signal = load_trial(row, dataset_type)\n    feats = extract_features(signal)\n    X.append(feats)\n    y.append(row['label'])\n\nX = np.array(X)\ny = np.array(y)\nprint(f\"✅ Extracted shape: {X.shape}, Labels: {y.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T19:42:32.177455Z","iopub.execute_input":"2025-06-30T19:42:32.178041Z","iopub.status.idle":"2025-06-30T19:45:34.491182Z","shell.execute_reply.started":"2025-06-30T19:42:32.178014Z","shell.execute_reply":"2025-06-30T19:45:34.490333Z"}},"outputs":[{"name":"stdout","text":"✅ Extracted shape: (2450, 32), Labels: (2450,)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# def extract_features(trial):  # shape: (4, 1750)\n#     features = []\n#     for ch in trial:\n#         features.extend([\n#             np.mean(ch),\n#             np.std(ch),\n#             np.max(ch),\n#             np.min(ch),\n#             np.sum(ch ** 2),  # energy\n#         ])\n#     return np.array(features)\n\n# X_feat = np.array([extract_features(trial) for trial in X_all])  # shape: (N, 4×5 = 20)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install lazypredict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T19:46:15.936818Z","iopub.execute_input":"2025-06-30T19:46:15.937158Z","iopub.status.idle":"2025-06-30T19:49:38.188093Z","shell.execute_reply.started":"2025-06-30T19:46:15.937135Z","shell.execute_reply":"2025-06-30T19:49:38.186917Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f1c37b8a7d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/lazypredict/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f1c3793abd0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/lazypredict/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f1c3791fd90>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/lazypredict/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f1c37a32110>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/lazypredict/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f1c3792af50>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/lazypredict/\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement lazypredict (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for lazypredict\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# Band power","metadata":{}},{"cell_type":"code","source":"bands = {\n    \"theta\": (6, 8),     # Could capture 7 Hz (Forward)\n    \"alpha\": (8, 10),    # Could capture 8 Hz (Backward)\n    \"mu\":    (10, 12),   # Could capture 10 Hz (Left)\n    \"beta\":  (12, 14),   # Could capture 13 Hz (Right)\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T20:05:08.885118Z","iopub.execute_input":"2025-06-27T20:05:08.885381Z","iopub.status.idle":"2025-06-27T20:05:08.889346Z","shell.execute_reply.started":"2025-06-27T20:05:08.885362Z","shell.execute_reply":"2025-06-27T20:05:08.888617Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from scipy.signal import welch\n\ndef bandpower(data, fs, band, window_sec=None):\n    band = np.asarray(band)\n    low, high = band\n    if window_sec is None:\n        nperseg = (2 / (high - low)) * fs  # Adaptive window\n    else:\n        nperseg = int(window_sec * fs)\n\n    freqs, psd = welch(data, fs=fs, nperseg=nperseg)\n    freq_res = freqs[1] - freqs[0]\n    \n    # Band power\n    idx_band = np.logical_and(freqs >= low, freqs <= high)\n    return np.sum(psd[idx_band]) * freq_res\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T20:05:09.346451Z","iopub.execute_input":"2025-06-27T20:05:09.346692Z","iopub.status.idle":"2025-06-27T20:05:09.894920Z","shell.execute_reply.started":"2025-06-27T20:05:09.346674Z","shell.execute_reply":"2025-06-27T20:05:09.894372Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def extract_bandpower_features(signal, fs=250):\n    # signal: (4 channels, 1750 samples)\n    bands = {\n        \"theta\": (6, 8),\n        \"alpha\": (8, 10),\n        \"mu\":    (10, 12),\n        \"beta\":  (12, 14),\n    }\n    \n    features = []\n    for ch in signal:\n        for band_range in bands.values():\n            bp = bandpower(ch, fs, band_range)\n            features.append(bp)\n    return np.array(features)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T20:05:11.064225Z","iopub.execute_input":"2025-06-27T20:05:11.064869Z","iopub.status.idle":"2025-06-27T20:05:11.069485Z","shell.execute_reply.started":"2025-06-27T20:05:11.064843Z","shell.execute_reply":"2025-06-27T20:05:11.068777Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"X = []\ny = []\n\nfor _, row in ssvep_df.iterrows():\n    dataset_type = 'train' if row['id'] <= 4800 else 'validation'\n    signal = load_trial(row, dataset_type)  # shape: (4, 1750)\n    features = extract_bandpower_features(signal, fs=250)\n    X.append(features)\n    y.append(row['label'])\n\nX = np.array(X)\ny = np.array(y)\nprint(\"✅ Band Power feature matrix:\", X.shape)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Wavelet","metadata":{}},{"cell_type":"code","source":"!pip install pywt\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pywt\nimport numpy as np\n\ndef extract_wavelet_energy(signal, wavelet='db4', level=4):\n    # signal shape: (4, 1750) → channels × samples\n    features = []\n\n    for ch in signal:\n        coeffs = pywt.wavedec(ch, wavelet=wavelet, level=level)\n        energies = [np.sum(np.square(c)) for c in coeffs]\n        features.extend(energies)\n\n    return np.array(features)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T20:05:20.348572Z","iopub.execute_input":"2025-06-27T20:05:20.349151Z","iopub.status.idle":"2025-06-27T20:05:20.414680Z","shell.execute_reply.started":"2025-06-27T20:05:20.349126Z","shell.execute_reply":"2025-06-27T20:05:20.413953Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"X_wavelet = []\ny_wavelet = []\n\nfor _, row in ssvep_df.iterrows():\n    dataset_type = 'train' if row['id'] <= 4800 else 'validation'\n    signal = load_trial(row, dataset_type)  # shape: (4, 1750)\n    features = extract_wavelet_energy(signal)\n    X_wavelet.append(features)\n    y_wavelet.append(row['label'])\n\nX_wavelet = np.array(X_wavelet)\ny_wavelet = np.array(y_wavelet)\nprint(f\"✅ Wavelet Energy features shape: {X_wavelet.shape}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from lazypredict.Supervised import LazyClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# Normalize\nX_scaled = StandardScaler().fit_transform(X_wavelet)\n\n# Train/test split\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y_wavelet, test_size=0.2, random_state=42)\n\n# Run LazyPredict\nclf = LazyClassifier(verbose=0, ignore_warnings=True)\nmodels, predictions = clf.fit(X_train, X_test, y_train, y_test)\n\nprint(models)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# combine band power and wavelet","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ndef compute_hjorth_parameters(signal):\n    \"\"\"\n    signal: np.array of shape (channels, time)\n    Returns: np.array of shape (channels × 3)\n    \"\"\"\n    features = []\n\n    for ch in signal:\n        first_deriv = np.diff(ch)\n        second_deriv = np.diff(first_deriv)\n\n        activity = np.var(ch)\n        mobility = np.sqrt(np.var(first_deriv) / activity) if activity != 0 else 0\n        complexity = (\n            np.sqrt(np.var(second_deriv) / np.var(first_deriv)) / mobility\n            if mobility != 0 and np.var(first_deriv) != 0\n            else 0\n        )\n\n        features.extend([activity, mobility, complexity])\n    \n    return np.array(features)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T20:18:23.688522Z","iopub.execute_input":"2025-06-27T20:18:23.688861Z","iopub.status.idle":"2025-06-27T20:18:23.694196Z","shell.execute_reply.started":"2025-06-27T20:18:23.688838Z","shell.execute_reply":"2025-06-27T20:18:23.693600Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"def extract_combined_features(signal, fs=250, wavelet='db4', level=4):\n    bandpower_features = extract_bandpower_features(signal, fs)\n    wavelet_features = extract_wavelet_energy(signal, wavelet, level)\n    return np.concatenate([bandpower_features, wavelet_features])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T20:18:24.321262Z","iopub.execute_input":"2025-06-27T20:18:24.321526Z","iopub.status.idle":"2025-06-27T20:18:24.325784Z","shell.execute_reply.started":"2025-06-27T20:18:24.321508Z","shell.execute_reply":"2025-06-27T20:18:24.325049Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"X_combined = []\ny_combined = []\n\nfor _, row in ssvep_df.iterrows():\n    dataset_type = 'train' if row['id'] <= 4800 else 'validation'\n    signal = load_trial(row, dataset_type)  # (4, 1750)\n    features = extract_combined_features(signal)\n    X_combined.append(features)\n    y_combined.append(row['label'])\n\nX_combined = np.array(X_combined)\ny_combined = np.array(y_combined)\n\nprint(\"✅ Combined feature shape:\", X_combined.shape)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom lazypredict.Supervised import LazyClassifier\n\n# Normalize\nX_scaled = StandardScaler().fit_transform(X_combined)\n\n# Train/test split\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y_combined, test_size=0.2, random_state=42)\n\n# LazyPredict\nclf = LazyClassifier(verbose=0, ignore_warnings=True)\nmodels, predictions = clf.fit(X_train, X_test, y_train, y_test)\n\nprint(models)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Filter by gyro","metadata":{}},{"cell_type":"code","source":"def load_trial_with_gyro_filter(row, dataset_type, movement_threshold=0.1):\n    eeg_path = f\"{base_path}/SSVEP/{dataset_type}/{row['subject_id']}/{row['trial_session']}/EEGdata.csv\"\n    eeg = pd.read_csv(eeg_path)\n\n    trial_num = int(row['trial'])\n    start = (trial_num - 1) * 1750\n    end = trial_num * 1750\n\n    # Extract EEG + gyro\n    eeg_segment = eeg[selected_channels].iloc[start:end].values.T.astype(np.float32)  # (4, 1750)\n    gyro_signal = eeg[['Gyro1', 'Gyro2', 'Gyro3']].iloc[start:end].values  # (1750, 3)\n\n    # Compute movement magnitude per sample\n    gyro_movement = np.linalg.norm(gyro_signal, axis=1)\n    gyro_std = np.std(gyro_movement)\n\n    # Skip this trial if movement is too high\n    if gyro_std > movement_threshold:\n        return None, True  # second return value flags skipped trial\n    return eeg_segment, False\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T20:05:29.095403Z","iopub.execute_input":"2025-06-27T20:05:29.096314Z","iopub.status.idle":"2025-06-27T20:05:29.101250Z","shell.execute_reply.started":"2025-06-27T20:05:29.096291Z","shell.execute_reply":"2025-06-27T20:05:29.100536Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def extract_gyro_features(gyro_signal):\n    # gyro_signal: (3, 1750)\n    features = []\n    for g in gyro_signal:\n        features.extend([\n            np.mean(g), np.std(g), np.min(g), np.max(g),\n            np.sum(g**2),  # Energy\n            np.sqrt(np.mean(g**2))  # RMS\n        ])\n    return np.array(features)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T20:05:29.364491Z","iopub.execute_input":"2025-06-27T20:05:29.364745Z","iopub.status.idle":"2025-06-27T20:05:29.369084Z","shell.execute_reply.started":"2025-06-27T20:05:29.364727Z","shell.execute_reply":"2025-06-27T20:05:29.368479Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"\nfrom scipy.signal import butter, filtfilt\n\ndef bandpass_filter(data, lowcut=5, highcut=45, fs=250, order=4):\n    \"\"\"\n    Apply a Butterworth bandpass filter to EEG data.\n    \n    Parameters:\n    - data: np.ndarray, shape (n_channels, n_samples)\n    - lowcut: float, low frequency cutoff\n    - highcut: float, high frequency cutoff\n    - fs: float, sampling rate\n    - order: int, filter order\n    \n    Returns:\n    - filtered_data: np.ndarray, shape (n_channels, n_samples)\n    \"\"\"\n    nyquist = 0.5 * fs\n    low = lowcut / nyquist\n    high = highcut / nyquist\n\n    b, a = butter(order, [low, high], btype='band')\n    filtered_data = filtfilt(b, a, data, axis=-1)  # filter each channel\n    return filtered_data\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T20:05:30.627998Z","iopub.execute_input":"2025-06-27T20:05:30.628449Z","iopub.status.idle":"2025-06-27T20:05:30.633233Z","shell.execute_reply.started":"2025-06-27T20:05:30.628429Z","shell.execute_reply":"2025-06-27T20:05:30.632467Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def augment_gaussian_noise(eeg, noise_std=0.01):\n    noise = np.random.normal(0, noise_std, eeg.shape)\n    return eeg + noise\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T20:05:32.645509Z","iopub.execute_input":"2025-06-27T20:05:32.646085Z","iopub.status.idle":"2025-06-27T20:05:32.649938Z","shell.execute_reply.started":"2025-06-27T20:05:32.646063Z","shell.execute_reply":"2025-06-27T20:05:32.649181Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def augment_time_shift(eeg, shift_samples=10):\n    return np.roll(eeg, shift=shift_samples, axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T20:05:32.799260Z","iopub.execute_input":"2025-06-27T20:05:32.799460Z","iopub.status.idle":"2025-06-27T20:05:32.803124Z","shell.execute_reply.started":"2025-06-27T20:05:32.799445Z","shell.execute_reply":"2025-06-27T20:05:32.802523Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def augment_amplitude_scale(eeg, scale_range=(0.9, 1.1)):\n    scale = np.random.uniform(*scale_range, (eeg.shape[0], 1))\n    return eeg * scale\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T20:05:33.078639Z","iopub.execute_input":"2025-06-27T20:05:33.078883Z","iopub.status.idle":"2025-06-27T20:05:33.082716Z","shell.execute_reply.started":"2025-06-27T20:05:33.078867Z","shell.execute_reply":"2025-06-27T20:05:33.082005Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def augment_eeg(eeg, methods=['noise', 'shift', 'scale']):\n    if 'noise' in methods:\n        eeg = augment_gaussian_noise(eeg)\n    if 'shift' in methods:\n        eeg = augment_time_shift(eeg, shift_samples=np.random.randint(-10, 10))\n    if 'scale' in methods:\n        eeg = augment_amplitude_scale(eeg)\n    return eeg\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T20:05:34.329768Z","iopub.execute_input":"2025-06-27T20:05:34.330038Z","iopub.status.idle":"2025-06-27T20:05:34.334951Z","shell.execute_reply.started":"2025-06-27T20:05:34.330017Z","shell.execute_reply":"2025-06-27T20:05:34.333855Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"ssvep_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T20:05:36.132704Z","iopub.execute_input":"2025-06-27T20:05:36.132969Z","iopub.status.idle":"2025-06-27T20:05:36.153162Z","shell.execute_reply.started":"2025-06-27T20:05:36.132949Z","shell.execute_reply":"2025-06-27T20:05:36.152563Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"        id subject_id   task  trial_session  trial  label\n0     2401         S1  SSVEP              1      1      2\n1     2402         S1  SSVEP              1      2      0\n2     2403         S1  SSVEP              1      3      3\n3     2404         S1  SSVEP              1      4      0\n4     2405         S1  SSVEP              1      5      0\n...    ...        ...    ...            ...    ...    ...\n2445  4896        S35  SSVEP              1      6      1\n2446  4897        S35  SSVEP              1      7      0\n2447  4898        S35  SSVEP              1      8      2\n2448  4899        S35  SSVEP              1      9      3\n2449  4900        S35  SSVEP              1     10      3\n\n[2450 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>subject_id</th>\n      <th>task</th>\n      <th>trial_session</th>\n      <th>trial</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2401</td>\n      <td>S1</td>\n      <td>SSVEP</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2402</td>\n      <td>S1</td>\n      <td>SSVEP</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2403</td>\n      <td>S1</td>\n      <td>SSVEP</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2404</td>\n      <td>S1</td>\n      <td>SSVEP</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2405</td>\n      <td>S1</td>\n      <td>SSVEP</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2445</th>\n      <td>4896</td>\n      <td>S35</td>\n      <td>SSVEP</td>\n      <td>1</td>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2446</th>\n      <td>4897</td>\n      <td>S35</td>\n      <td>SSVEP</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2447</th>\n      <td>4898</td>\n      <td>S35</td>\n      <td>SSVEP</td>\n      <td>1</td>\n      <td>8</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2448</th>\n      <td>4899</td>\n      <td>S35</td>\n      <td>SSVEP</td>\n      <td>1</td>\n      <td>9</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2449</th>\n      <td>4900</td>\n      <td>S35</td>\n      <td>SSVEP</td>\n      <td>1</td>\n      <td>10</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>2450 rows × 6 columns</p>\n</div>"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":" def sliding_window_augment(X, y, window_size=100, stride=100):\n    aug_X = []\n    aug_y = []\n    for trial, label in zip(X, y):\n        # print(trial.shape[0])\n        for start in range(0, trial.shape[0] - window_size + 1, stride):\n            \n            window = trial[start:start + window_size]\n            aug_X.append(window)\n            aug_y.append(label)\n    return np.array(aug_X), np.array(aug_y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T20:05:37.312661Z","iopub.execute_input":"2025-06-27T20:05:37.313080Z","iopub.status.idle":"2025-06-27T20:05:37.318977Z","shell.execute_reply.started":"2025-06-27T20:05:37.313056Z","shell.execute_reply":"2025-06-27T20:05:37.318241Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"print(\" Applying sliding window augmentation...\")\naug_X_train, aug_y_train = sliding_window_augment(X_train, y_train, window_size=32, stride=4)\n# aug_X_val_MI, aug_y_val_MI = sliding_window_augment(pre_X_val_MI, y_val_MI, window_size=200, stride=200)\nprint(f\" Augmented MI training set shape: {aug_X_train.shape}, Labels: {aug_y_train.shape}\")\n# print(f\" Augmented MI validate set shape: {aug_X_val_MI.shape}, Labels: {aug_y_val_MI.shape}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def apply_car(eeg_signal):\n    \"\"\"\n    Apply Common Average Referencing (CAR) to EEG data.\n    \n    eeg_signal: np.ndarray of shape (channels, samples)\n    \"\"\"\n    average = np.mean(eeg_signal, axis=0)           # Shape: (samples,)\n    eeg_car = eeg_signal - average                  # Subtract from each channel\n    return eeg_car\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T20:07:58.888594Z","iopub.execute_input":"2025-06-27T20:07:58.889119Z","iopub.status.idle":"2025-06-27T20:07:58.892737Z","shell.execute_reply.started":"2025-06-27T20:07:58.889097Z","shell.execute_reply":"2025-06-27T20:07:58.892049Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"selected_channels = ['OZ', 'PZ', 'CZ', 'PO8']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T20:05:42.812871Z","iopub.execute_input":"2025-06-27T20:05:42.813700Z","iopub.status.idle":"2025-06-27T20:05:42.817083Z","shell.execute_reply.started":"2025-06-27T20:05:42.813671Z","shell.execute_reply":"2025-06-27T20:05:42.816223Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"def apply_car(eeg_signal):\n    \"\"\"\n    Apply Common Average Referencing (CAR) to EEG data.\n    eeg_signal: shape (channels, time)\n    \"\"\"\n    mean_across_channels = np.mean(eeg_signal, axis=0)  # shape: (time,)\n    return eeg_signal - mean_across_channels\n\n# Main data processing loop\nX_combined = []\ny_combined = []\naug_factor = 2\n\nfor _, row in ssvep_df.iterrows():\n    dataset_type = 'train' if row['id'] <= 4800 else 'validation'\n\n    # Load EEG file\n    eeg_path = f\"{base_path}/SSVEP/{dataset_type}/{row['subject_id']}/{row['trial_session']}/EEGdata.csv\"\n    eeg = pd.read_csv(eeg_path)\n\n    trial_num = int(row['trial'])\n    start = (trial_num - 1) * 1750\n    end = trial_num * 1750\n\n    # Select EEG and Gyro\n    eeg_segment = eeg[selected_channels].iloc[start:end].values.T.astype(np.float32)\n    gyro_segment = eeg[['Gyro1', 'Gyro2', 'Gyro3']].iloc[start:end].values.T.astype(np.float32)\n\n    # Filter noisy trial using gyro\n    gyro_movement = np.linalg.norm(gyro_segment.T, axis=1)\n    if np.std(gyro_movement) > 3:\n        continue  # Skip noisy trial\n\n    # Apply CAR to EEG\n    eeg_car = apply_car(eeg_segment)\n\n    # Apply bandpass filter\n    filtered = bandpass_filter(eeg_car, lowcut=5, highcut=45, fs=250)\n\n    # Extract features\n    eeg_features = extract_combined_features(filtered)  # Band Power + Wavelet\n    gyro_features = extract_gyro_features(gyro_segment)\n\n    full_features = np.concatenate([eeg_features, gyro_features])\n    X_combined.append(full_features)\n    y_combined.append(row['label'])\n\nX_combined = np.array(X_combined)\ny_combined = np.array(y_combined)\n\nprint(\"✅ Final feature shape (EEG + Gyro):\", X_combined.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T20:18:39.737379Z","iopub.execute_input":"2025-06-27T20:18:39.738259Z","iopub.status.idle":"2025-06-27T20:20:59.925307Z","shell.execute_reply.started":"2025-06-27T20:18:39.738228Z","shell.execute_reply":"2025-06-27T20:20:59.924510Z"}},"outputs":[{"name":"stdout","text":"✅ Final feature shape (EEG + Gyro): (2117, 54)\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest, f_classif\nselector = SelectKBest(score_func=f_classif, k=40)\nX_selected = selector.fit_transform(X_combined, y_combined)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T19:50:46.204095Z","iopub.execute_input":"2025-06-27T19:50:46.204782Z","iopub.status.idle":"2025-06-27T19:50:46.218964Z","shell.execute_reply.started":"2025-06-27T19:50:46.204757Z","shell.execute_reply":"2025-06-27T19:50:46.218137Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"!pip install lazypredict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T20:12:22.063966Z","iopub.execute_input":"2025-06-27T20:12:22.064459Z","iopub.status.idle":"2025-06-27T20:12:32.537780Z","shell.execute_reply.started":"2025-06-27T20:12:22.064436Z","shell.execute_reply":"2025-06-27T20:12:32.537063Z"}},"outputs":[{"name":"stdout","text":"Collecting lazypredict\n  Downloading lazypredict-0.2.16-py2.py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from lazypredict) (8.1.8)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from lazypredict) (1.2.2)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from lazypredict) (2.2.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from lazypredict) (4.67.1)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from lazypredict) (1.5.0)\nRequirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (from lazypredict) (4.6.0)\nRequirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (from lazypredict) (2.0.3)\nCollecting pytest-runner (from lazypredict)\n  Downloading pytest_runner-6.0.1-py3-none-any.whl.metadata (7.3 kB)\nCollecting mlflow>=2.0.0 (from lazypredict)\n  Downloading mlflow-3.1.1-py3-none-any.whl.metadata (29 kB)\nCollecting mlflow-skinny==3.1.1 (from mlflow>=2.0.0->lazypredict)\n  Downloading mlflow_skinny-3.1.1-py3-none-any.whl.metadata (30 kB)\nRequirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow>=2.0.0->lazypredict) (3.1.0)\nRequirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.11/dist-packages (from mlflow>=2.0.0->lazypredict) (1.15.2)\nRequirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow>=2.0.0->lazypredict) (7.1.0)\nCollecting graphene<4 (from mlflow>=2.0.0->lazypredict)\n  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\nCollecting gunicorn<24 (from mlflow>=2.0.0->lazypredict)\n  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\nRequirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow>=2.0.0->lazypredict) (3.7.2)\nRequirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from mlflow>=2.0.0->lazypredict) (1.26.4)\nRequirement already satisfied: pyarrow<21,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow>=2.0.0->lazypredict) (19.0.1)\nRequirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from mlflow>=2.0.0->lazypredict) (1.15.2)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow>=2.0.0->lazypredict) (2.0.40)\nRequirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict) (5.5.2)\nRequirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict) (3.1.1)\nCollecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict)\n  Downloading databricks_sdk-0.57.0-py3-none-any.whl.metadata (39 kB)\nCollecting fastapi<1 (from mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict)\n  Downloading fastapi-0.115.14-py3-none-any.whl.metadata (27 kB)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict) (3.1.44)\nRequirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict) (8.7.0)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict) (1.31.1)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict) (1.31.1)\nRequirement already satisfied: packaging<26 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict) (25.0)\nRequirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict) (3.20.3)\nRequirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict) (2.11.4)\nRequirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict) (6.0.2)\nRequirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict) (2.32.3)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict) (0.5.3)\nRequirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict) (4.13.2)\nCollecting uvicorn<1 (from mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict)\n  Downloading uvicorn-0.34.3-py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->lazypredict) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->lazypredict) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->lazypredict) (2025.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->lazypredict) (3.6.0)\nRequirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic!=1.10.0,<2->mlflow>=2.0.0->lazypredict) (1.3.10)\nRequirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow>=2.0.0->lazypredict) (2.4.0)\nRequirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow>=2.0.0->lazypredict) (3.1.3)\nRequirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow>=2.0.0->lazypredict) (3.1.6)\nRequirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow>=2.0.0->lazypredict) (2.2.0)\nRequirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow>=2.0.0->lazypredict) (1.9.0)\nCollecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow>=2.0.0->lazypredict)\n  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\nCollecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow>=2.0.0->lazypredict)\n  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow>=2.0.0->lazypredict) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow>=2.0.0->lazypredict) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow>=2.0.0->lazypredict) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow>=2.0.0->lazypredict) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow>=2.0.0->lazypredict) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow>=2.0.0->lazypredict) (3.0.9)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow>=2.0.0->lazypredict) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow>=2.0.0->lazypredict) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow>=2.0.0->lazypredict) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow>=2.0.0->lazypredict) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow>=2.0.0->lazypredict) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow>=2.0.0->lazypredict) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->lazypredict) (1.17.0)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow>=2.0.0->lazypredict) (3.1.1)\nRequirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict) (2.40.1)\nCollecting starlette<0.47.0,>=0.40.0 (from fastapi<1->mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict)\n  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict) (4.0.12)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict) (3.21.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->Flask<4->mlflow>=2.0.0->lazypredict) (3.0.2)\nRequirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict) (1.2.18)\nCollecting importlib_metadata!=4.7.0,<9,>=3.7.0 (from mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict)\n  Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.52b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict) (0.52b1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict) (3.10)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict) (2025.4.26)\nRequirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1->mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict) (0.14.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3->mlflow>=2.0.0->lazypredict) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3->mlflow>=2.0.0->lazypredict) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3->mlflow>=2.0.0->lazypredict) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3->mlflow>=2.0.0->lazypredict) (2024.2.0)\nRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict) (1.17.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict) (5.0.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict) (4.9.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3->mlflow>=2.0.0->lazypredict) (2024.2.0)\nRequirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict) (4.9.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict) (1.3.1)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow>=2.0.0->lazypredict) (0.6.1)\nDownloading lazypredict-0.2.16-py2.py3-none-any.whl (14 kB)\nDownloading mlflow-3.1.1-py3-none-any.whl (24.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.7/24.7 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading mlflow_skinny-3.1.1-py3-none-any.whl (1.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pytest_runner-6.0.1-py3-none-any.whl (7.2 kB)\nDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading databricks_sdk-0.57.0-py3-none-any.whl (733 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m733.8/733.8 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastapi-0.115.14-py3-none-any.whl (95 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.5/95.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\nDownloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\nDownloading uvicorn-0.34.3-py3-none-any.whl (62 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading starlette-0.46.2-py3-none-any.whl (72 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: uvicorn, pytest-runner, importlib_metadata, gunicorn, graphql-core, starlette, graphql-relay, graphene, fastapi, databricks-sdk, mlflow-skinny, mlflow, lazypredict\n  Attempting uninstall: importlib_metadata\n    Found existing installation: importlib_metadata 8.7.0\n    Uninstalling importlib_metadata-8.7.0:\n      Successfully uninstalled importlib_metadata-8.7.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed databricks-sdk-0.57.0 fastapi-0.115.14 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 importlib_metadata-8.6.1 lazypredict-0.2.16 mlflow-3.1.1 mlflow-skinny-3.1.1 pytest-runner-6.0.1 starlette-0.46.2 uvicorn-0.34.3\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom lazypredict.Supervised import LazyClassifier\n\nX_scaled = StandardScaler().fit_transform(X_combined)\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y_combined, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T20:21:36.727271Z","iopub.execute_input":"2025-06-27T20:21:36.727861Z","iopub.status.idle":"2025-06-27T20:21:36.735552Z","shell.execute_reply.started":"2025-06-27T20:21:36.727837Z","shell.execute_reply":"2025-06-27T20:21:36.734956Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"len(X_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T20:13:04.586983Z","iopub.execute_input":"2025-06-27T20:13:04.587248Z","iopub.status.idle":"2025-06-27T20:13:04.592199Z","shell.execute_reply.started":"2025-06-27T20:13:04.587229Z","shell.execute_reply":"2025-06-27T20:13:04.591664Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"1693"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"!pip install -U scikit-learn imbalanced-learn --quiet\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip uninstall scikit-learn imbalanced-learn -y","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install scikit-learn==1.3.0 imbalanced-learn==0.10.1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\nclf = LazyClassifier(verbose=0, ignore_warnings=True)\nmodels, predictions = clf.fit(X_train, X_test, y_train, y_test)\nprint(models)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T20:21:52.661465Z","iopub.execute_input":"2025-06-27T20:21:52.661757Z","iopub.status.idle":"2025-06-27T20:22:05.369474Z","shell.execute_reply.started":"2025-06-27T20:21:52.661735Z","shell.execute_reply":"2025-06-27T20:22:05.368651Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dece3822b4e5479da1bb80bed3cbab92"}},"metadata":{}},{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000559 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13185\n[LightGBM] [Info] Number of data points in the train set: 1693, number of used features: 54\n[LightGBM] [Info] Start training from score -1.408391\n[LightGBM] [Info] Start training from score -1.445296\n[LightGBM] [Info] Start training from score -1.403572\n[LightGBM] [Info] Start training from score -1.294373\n                               Accuracy  Balanced Accuracy ROC AUC  F1 Score  \\\nModel                                                                          \nXGBClassifier                      0.49               0.49    None      0.48   \nRandomForestClassifier             0.48               0.48    None      0.47   \nLGBMClassifier                     0.47               0.47    None      0.47   \nAdaBoostClassifier                 0.46               0.46    None      0.46   \nBaggingClassifier                  0.45               0.45    None      0.44   \nExtraTreesClassifier               0.45               0.45    None      0.45   \nRidgeClassifierCV                  0.41               0.41    None      0.40   \nRidgeClassifier                    0.40               0.41    None      0.40   \nLogisticRegression                 0.40               0.41    None      0.39   \nLinearSVC                          0.39               0.40    None      0.39   \nCalibratedClassifierCV             0.39               0.39    None      0.37   \nLinearDiscriminantAnalysis         0.39               0.39    None      0.38   \nNuSVC                              0.39               0.39    None      0.39   \nDecisionTreeClassifier             0.38               0.38    None      0.38   \nLabelPropagation                   0.37               0.37    None      0.37   \nLabelSpreading                     0.37               0.37    None      0.37   \nSVC                                0.35               0.35    None      0.31   \nSGDClassifier                      0.35               0.35    None      0.34   \nKNeighborsClassifier               0.34               0.35    None      0.34   \nNearestCentroid                    0.32               0.33    None      0.31   \nExtraTreeClassifier                0.31               0.32    None      0.31   \nPassiveAggressiveClassifier        0.31               0.31    None      0.27   \nPerceptron                         0.30               0.30    None      0.30   \nBernoulliNB                        0.29               0.29    None      0.29   \nDummyClassifier                    0.27               0.25    None      0.11   \nQuadraticDiscriminantAnalysis      0.23               0.25    None      0.15   \nGaussianNB                         0.21               0.24    None      0.10   \n\n                               Time Taken  \nModel                                      \nXGBClassifier                        1.59  \nRandomForestClassifier               0.99  \nLGBMClassifier                       1.10  \nAdaBoostClassifier                   0.59  \nBaggingClassifier                    0.62  \nExtraTreesClassifier                 0.35  \nRidgeClassifierCV                    0.02  \nRidgeClassifier                      0.02  \nLogisticRegression                   0.64  \nLinearSVC                            1.08  \nCalibratedClassifierCV               4.07  \nLinearDiscriminantAnalysis           0.02  \nNuSVC                                0.52  \nDecisionTreeClassifier               0.10  \nLabelPropagation                     0.19  \nLabelSpreading                       0.23  \nSVC                                  0.29  \nSGDClassifier                        0.06  \nKNeighborsClassifier                 0.03  \nNearestCentroid                      0.02  \nExtraTreeClassifier                  0.01  \nPassiveAggressiveClassifier          0.03  \nPerceptron                           0.03  \nBernoulliNB                          0.02  \nDummyClassifier                      0.01  \nQuadraticDiscriminantAnalysis        0.02  \nGaussianNB                           0.01  \n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"from lightgbm import LGBMClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Initialize the classifier\nlgbm = LGBMClassifier(random_state=42)\n\n# Train the model\nlgbm.fit(X_aug, y_aug)\n\n# Predict on test data\ny_pred = lgbm.predict(X_test)\n\n# Evaluate\nacc = accuracy_score(y_test, y_pred)\nprint(f\"✅ Accuracy on test set: {acc:.4f}\")\nprint(\"\\n📊 Classification Report:\")\nprint(classification_report(y_test, y_pred))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# SSVEPformer","metadata":{}},{"cell_type":"code","source":"# Okba Bekhelifi dec 2024, <okba.bekhelifi@univ-usto.dz>\n# Implements SSVEPFormer model from:\n# Chen, J. et al. (2023) ‘A transformer-based deep neural network model for SSVEP classification’, \n# Neural Networks, 164, pp. 521–534. Available at: https://doi.org/10.1016/j.neunet.2023.04.045.\n#\n#\n\nfrom torch import flatten\nfrom torch import nn\nimport torch.nn.functional as F\n\nclass ChComb(nn.Module):\n  def __init__(self, Chans=8, Samples=220, dropout=0.5):\n    super().__init__()\n    self.conv = nn.Conv1d(Chans // 2, Chans, 1, padding='same')\n    self.ln   = nn.LayerNorm(Samples)\n    self.act  = nn.GELU()\n    self.do   = nn.Dropout(p=dropout)\n\n  def forward(self, x):\n    return self.do(self.act(self.ln(self.conv(x))))\n\nclass Encoder(nn.Module):\n  def __init__(self, Chans=16, Samples=220, dropout=0.5):\n    super().__init__()\n    # CNN module\n    self.channels = Chans\n    self.ln1  = nn.LayerNorm(Samples)\n    self.conv = nn.Conv1d(Chans, Chans, 31, padding='same')\n    self.ln2  = nn.LayerNorm(Samples)\n    self.act  = nn.GELU()\n    self.do   = nn.Dropout(p=dropout)\n    # MLP module\n    self.ln3  = nn.LayerNorm(Samples)\n    self.proj = nn.Linear(Chans, Samples)\n    self.do2  = nn.Dropout(p=dropout)\n\n  def forward(self, x):\n    #\n    shortcut1 = x\n    x = self.conv(self.ln1(x))\n    x = self.act(self.ln2(x))\n    x = self.do(x) + shortcut1\n    shortcut2 = x\n    #\n    x = self.ln3(x)\n    output_channels = []\n    for i in range(self.channels):\n      c = self.proj(x[:,:,i])\n      c = c.unsqueeze(1)\n      output_channels.append(c)\n    x = torch.cat(output_channels, 1)\n    x = self.do(x) + shortcut2\n    return x\n\nclass MlpHead(nn.Module):\n  def __init__(self, Chans, Samples, n_classes, drop_rate=0.5):\n    super().__init__()\n    self.drop       = nn.Dropout(drop_rate)\n    self.linear1    = nn.Linear(Chans * Samples, 6 * n_classes)\n    self.norm       = nn.LayerNorm(6*n_classes)\n    self.activation = nn.GELU()\n    self.drop2      = nn.Dropout(drop_rate)\n    self.linear2    = nn.Linear(6*n_classes, n_classes)\n\n  def forward(self, x):\n    x = flatten(x, 1)\n    x = self.drop(x)\n    x = self.linear1(x)\n    x = self.norm(x)\n    x = self.activation(x)\n    x = self.drop2(x)\n    x = self.linear2(x)\n    return x\n\nclass SSVEPFormerTH(nn.Module):\n  def __init__(self, Chans=8, n_classes=12, fs=256,\n               band=[8, 64], resolution=0.25, \n               drop_rate=0.25):\n    super().__init__()\n    self.name = \"SSVEPFORMER\"\n    self.fs = fs\n    self.resolution = resolution\n    self.nfft  = round(fs / resolution)\n    self.fft_start = int(round(band[0] / self.resolution))\n    self.fft_end   = int(round(band[1] / self.resolution)) + 1\n    samples = (self.fft_end - self.fft_start) * 2\n    filters = 2*Chans\n\n    self.channel_comb = ChComb(filters,  samples, drop_rate)\n    self.encoder1     = Encoder(filters, samples, drop_rate)\n    self.encoder2     = Encoder(filters, samples, drop_rate)\n    self.head         = MlpHead(filters, samples, n_classes, drop_rate)\n\n    self.init_weights()\n\n  def init_weights(self):\n    for module in self.modules():\n        if hasattr(module, 'weight'):\n          cls_name = module.__class__.__name__\n          if not(\"BatchNorm\" in cls_name or \"LayerNorm\" in cls_name):\n            nn.init.normal_(module.weight, mean=0.0, std=0.01)\n          else:\n            nn.init.constant_(module.weight, 1)\n          if hasattr(module, \"bias\"):\n            if module.bias is not None:\n              nn.init.constant_(module.bias, 0)\n\n  def forward(self, x):\n    x = self.transform(x)\n    x = self.channel_comb(x)\n    x = self.encoder1(x)\n    x = self.encoder2(x)\n    x = self.head(x)\n    return x\n\n  def transform(self, x):\n    with torch.no_grad():\n      samples = x.shape[-1]\n      x = torch.fft.fft(x, n=self.nfft) / samples\n      real = x.real[:,:, self.fft_start:self.fft_end]\n      imag = x.imag[:,:, self.fft_start:self.fft_end]\n      x = torch.cat((real, imag), axis=-1)\n    return x\n\n\nclass FBSSVEPFormer(nn.Module):\n  def __init__(self, fs=256, n_subbands=3, models=None):\n    super().__init__()\n    self.name = \"FB-SSVEPFORMER\"\n    self.fs = fs\n    self.subbands = [[8*i, 80] for i in range(1, n_subbands+1)]\n    self.subnets  = models\n    self.conv     = nn.Conv1d(n_subbands, 1, 1, padding='same')\n    self.init_weights()\n\n  def init_weights(self):\n    nn.init.normal_(self.conv.weight, mean=0.0, std=0.01)\n    nn.init.constant_(self.conv.bias, 0)\n\n  def forward(self, x):\n    out = []\n    for i, band in enumerate(self.subbands):\n      c = self.filter_band(x, band)\n      c = self.subnets[i](c)\n      c = c.unsqueeze(1)\n      out.append(c)\n    #\n    x = torch.cat(out, 1)\n    x = self.conv(x)\n    return x.squeeze(1)\n\n  def filter_band(self, x, band):\n    # x: batch, channels, samples\n    device = x.device\n    with torch.no_grad():\n      x = x.cpu().numpy()\n      B, A = butter(4, np.array(band) / (self.fs / 2), btype='bandpass')\n      x = filtfilt(B, A, x, axis=-1)\n      x = x.copy()\n    return torch.tensor(x, dtype=torch.float, device=device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T20:22:20.035017Z","iopub.execute_input":"2025-06-27T20:22:20.035586Z","iopub.status.idle":"2025-06-27T20:22:20.054962Z","shell.execute_reply.started":"2025-06-27T20:22:20.035564Z","shell.execute_reply":"2025-06-27T20:22:20.054297Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# 1. Reshape data to (samples, 1, timepoints)\nX_tensor = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)\ny_tensor = torch.tensor(y_train, dtype=torch.long)\nX_test_tensor = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)\ny_test_tensor = torch.tensor(y_test, dtype=torch.long)\n\n# 2. Initialize model\nmodel = SSVEPFormerTH(\n    Chans=X_tensor.shape[1],  # Should be 1 after unsqueeze\n    n_classes=len(torch.unique(y_tensor)),\n    fs=250,\n    band=[8, 64]\n).to('cuda')\n\n# 3. Train as before...\ntrain_loader = DataLoader(TensorDataset(X_tensor, y_tensor), batch_size=128, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T20:22:36.449284Z","iopub.execute_input":"2025-06-27T20:22:36.449551Z","iopub.status.idle":"2025-06-27T20:22:36.460243Z","shell.execute_reply.started":"2025-06-27T20:22:36.449532Z","shell.execute_reply":"2025-06-27T20:22:36.459550Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"val_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=128)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T20:22:39.549223Z","iopub.execute_input":"2025-06-27T20:22:39.549839Z","iopub.status.idle":"2025-06-27T20:22:39.553526Z","shell.execute_reply.started":"2025-06-27T20:22:39.549817Z","shell.execute_reply":"2025-06-27T20:22:39.552935Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip uninstall optim -y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T20:03:23.511249Z","iopub.execute_input":"2025-06-27T20:03:23.511936Z","iopub.status.idle":"2025-06-27T20:03:24.667743Z","shell.execute_reply.started":"2025-06-27T20:03:23.511900Z","shell.execute_reply":"2025-06-27T20:03:24.666939Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: optim 0.1.0\nUninstalling optim-0.1.0:\n  Successfully uninstalled optim-0.1.0\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim  # ✅ This is what you're missing\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\nbest_val_loss = float('inf')\n\nfor epoch in range(1, 201):\n    model.train()\n    train_loss = 0\n    train_correct = 0\n\n    for x_batch, y_batch in train_loader:\n        x_batch, y_batch = x_batch.to('cuda'), y_batch.to('cuda')\n        optimizer.zero_grad()\n        output = model(x_batch)\n        loss = criterion(output, y_batch)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item() * x_batch.size(0)\n        train_correct += (output.argmax(dim=1) == y_batch).sum().item()\n\n    train_loss /= len(train_loader.dataset)\n    train_acc = train_correct / len(train_loader.dataset)\n\n    # Validation\n    model.eval()\n    val_loss = 0\n    val_correct = 0\n\n    with torch.no_grad():\n        for x_val, y_val in val_loader:\n            x_val, y_val = x_val.to('cuda'), y_val.to('cuda')\n            output = model(x_val)\n            loss = criterion(output, y_val)\n            val_loss += loss.item() * x_val.size(0)\n            val_correct += (output.argmax(dim=1) == y_val).sum().item()\n\n    val_loss /= len(val_loader.dataset)\n    val_acc = val_correct / len(val_loader.dataset)\n\n    print(f\"Epoch {epoch:03d} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n          f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T20:22:42.130227Z","iopub.execute_input":"2025-06-27T20:22:42.130796Z","iopub.status.idle":"2025-06-27T20:23:00.613220Z","shell.execute_reply.started":"2025-06-27T20:22:42.130775Z","shell.execute_reply":"2025-06-27T20:23:00.612537Z"}},"outputs":[{"name":"stdout","text":"Epoch 001 | Train Loss: 1.3850 | Train Acc: 0.2658 | Val Loss: 1.3788 | Val Acc: 0.3090\nEpoch 002 | Train Loss: 1.3741 | Train Acc: 0.3148 | Val Loss: 1.3676 | Val Acc: 0.3349\nEpoch 003 | Train Loss: 1.3586 | Train Acc: 0.3757 | Val Loss: 1.3536 | Val Acc: 0.3726\nEpoch 004 | Train Loss: 1.3450 | Train Acc: 0.3692 | Val Loss: 1.3395 | Val Acc: 0.3679\nEpoch 005 | Train Loss: 1.3261 | Train Acc: 0.3940 | Val Loss: 1.3331 | Val Acc: 0.3703\nEpoch 006 | Train Loss: 1.3089 | Train Acc: 0.4040 | Val Loss: 1.3199 | Val Acc: 0.3750\nEpoch 007 | Train Loss: 1.3037 | Train Acc: 0.4087 | Val Loss: 1.3284 | Val Acc: 0.3915\nEpoch 008 | Train Loss: 1.2902 | Train Acc: 0.4040 | Val Loss: 1.3087 | Val Acc: 0.4080\nEpoch 009 | Train Loss: 1.2759 | Train Acc: 0.4300 | Val Loss: 1.3130 | Val Acc: 0.3774\nEpoch 010 | Train Loss: 1.2728 | Train Acc: 0.4229 | Val Loss: 1.3042 | Val Acc: 0.3939\nEpoch 011 | Train Loss: 1.2657 | Train Acc: 0.4294 | Val Loss: 1.3041 | Val Acc: 0.4175\nEpoch 012 | Train Loss: 1.2612 | Train Acc: 0.4034 | Val Loss: 1.3008 | Val Acc: 0.4127\nEpoch 013 | Train Loss: 1.2591 | Train Acc: 0.4276 | Val Loss: 1.2866 | Val Acc: 0.3868\nEpoch 014 | Train Loss: 1.2500 | Train Acc: 0.4300 | Val Loss: 1.3003 | Val Acc: 0.3915\nEpoch 015 | Train Loss: 1.2439 | Train Acc: 0.4389 | Val Loss: 1.2936 | Val Acc: 0.4009\nEpoch 016 | Train Loss: 1.2457 | Train Acc: 0.4182 | Val Loss: 1.2945 | Val Acc: 0.3962\nEpoch 017 | Train Loss: 1.2391 | Train Acc: 0.4436 | Val Loss: 1.2925 | Val Acc: 0.3939\nEpoch 018 | Train Loss: 1.2299 | Train Acc: 0.4389 | Val Loss: 1.2850 | Val Acc: 0.4009\nEpoch 019 | Train Loss: 1.2383 | Train Acc: 0.4347 | Val Loss: 1.2858 | Val Acc: 0.4175\nEpoch 020 | Train Loss: 1.2300 | Train Acc: 0.4442 | Val Loss: 1.2824 | Val Acc: 0.4104\nEpoch 021 | Train Loss: 1.2087 | Train Acc: 0.4637 | Val Loss: 1.2796 | Val Acc: 0.4151\nEpoch 022 | Train Loss: 1.2209 | Train Acc: 0.4542 | Val Loss: 1.2935 | Val Acc: 0.3962\nEpoch 023 | Train Loss: 1.2211 | Train Acc: 0.4507 | Val Loss: 1.2946 | Val Acc: 0.3986\nEpoch 024 | Train Loss: 1.2310 | Train Acc: 0.4335 | Val Loss: 1.2888 | Val Acc: 0.4009\nEpoch 025 | Train Loss: 1.2161 | Train Acc: 0.4477 | Val Loss: 1.2860 | Val Acc: 0.4104\nEpoch 026 | Train Loss: 1.2065 | Train Acc: 0.4519 | Val Loss: 1.2845 | Val Acc: 0.4151\nEpoch 027 | Train Loss: 1.2004 | Train Acc: 0.4607 | Val Loss: 1.2823 | Val Acc: 0.3939\nEpoch 028 | Train Loss: 1.2052 | Train Acc: 0.4649 | Val Loss: 1.2753 | Val Acc: 0.4127\nEpoch 029 | Train Loss: 1.2146 | Train Acc: 0.4542 | Val Loss: 1.2792 | Val Acc: 0.4127\nEpoch 030 | Train Loss: 1.2037 | Train Acc: 0.4595 | Val Loss: 1.2799 | Val Acc: 0.4151\nEpoch 031 | Train Loss: 1.1984 | Train Acc: 0.4637 | Val Loss: 1.2766 | Val Acc: 0.4222\nEpoch 032 | Train Loss: 1.1895 | Train Acc: 0.4566 | Val Loss: 1.2797 | Val Acc: 0.4198\nEpoch 033 | Train Loss: 1.1925 | Train Acc: 0.4542 | Val Loss: 1.2773 | Val Acc: 0.4033\nEpoch 034 | Train Loss: 1.2004 | Train Acc: 0.4572 | Val Loss: 1.2867 | Val Acc: 0.4151\nEpoch 035 | Train Loss: 1.2040 | Train Acc: 0.4460 | Val Loss: 1.2766 | Val Acc: 0.4009\nEpoch 036 | Train Loss: 1.2003 | Train Acc: 0.4560 | Val Loss: 1.2765 | Val Acc: 0.4387\nEpoch 037 | Train Loss: 1.1841 | Train Acc: 0.4631 | Val Loss: 1.2797 | Val Acc: 0.4175\nEpoch 038 | Train Loss: 1.1843 | Train Acc: 0.4584 | Val Loss: 1.2776 | Val Acc: 0.4198\nEpoch 039 | Train Loss: 1.1881 | Train Acc: 0.4607 | Val Loss: 1.2816 | Val Acc: 0.4033\nEpoch 040 | Train Loss: 1.1832 | Train Acc: 0.4778 | Val Loss: 1.2741 | Val Acc: 0.4080\nEpoch 041 | Train Loss: 1.1713 | Train Acc: 0.4843 | Val Loss: 1.2793 | Val Acc: 0.4009\nEpoch 042 | Train Loss: 1.1839 | Train Acc: 0.4666 | Val Loss: 1.2908 | Val Acc: 0.4009\nEpoch 043 | Train Loss: 1.1754 | Train Acc: 0.4584 | Val Loss: 1.2838 | Val Acc: 0.4151\nEpoch 044 | Train Loss: 1.1762 | Train Acc: 0.4696 | Val Loss: 1.2834 | Val Acc: 0.4151\nEpoch 045 | Train Loss: 1.1738 | Train Acc: 0.4643 | Val Loss: 1.2785 | Val Acc: 0.3962\nEpoch 046 | Train Loss: 1.1769 | Train Acc: 0.4708 | Val Loss: 1.2817 | Val Acc: 0.4080\nEpoch 047 | Train Loss: 1.1717 | Train Acc: 0.4566 | Val Loss: 1.2831 | Val Acc: 0.4222\nEpoch 048 | Train Loss: 1.1743 | Train Acc: 0.4773 | Val Loss: 1.2862 | Val Acc: 0.3939\nEpoch 049 | Train Loss: 1.1788 | Train Acc: 0.4672 | Val Loss: 1.2801 | Val Acc: 0.4127\nEpoch 050 | Train Loss: 1.1621 | Train Acc: 0.4879 | Val Loss: 1.2883 | Val Acc: 0.4080\nEpoch 051 | Train Loss: 1.1628 | Train Acc: 0.4891 | Val Loss: 1.2772 | Val Acc: 0.4080\nEpoch 052 | Train Loss: 1.1661 | Train Acc: 0.4773 | Val Loss: 1.2848 | Val Acc: 0.4057\nEpoch 053 | Train Loss: 1.1749 | Train Acc: 0.4814 | Val Loss: 1.2875 | Val Acc: 0.4198\nEpoch 054 | Train Loss: 1.1651 | Train Acc: 0.4790 | Val Loss: 1.2900 | Val Acc: 0.4175\nEpoch 055 | Train Loss: 1.1590 | Train Acc: 0.4914 | Val Loss: 1.2869 | Val Acc: 0.4127\nEpoch 056 | Train Loss: 1.1556 | Train Acc: 0.4920 | Val Loss: 1.2929 | Val Acc: 0.4009\nEpoch 057 | Train Loss: 1.1539 | Train Acc: 0.4802 | Val Loss: 1.3010 | Val Acc: 0.4057\nEpoch 058 | Train Loss: 1.1423 | Train Acc: 0.4938 | Val Loss: 1.2936 | Val Acc: 0.4222\nEpoch 059 | Train Loss: 1.1493 | Train Acc: 0.4926 | Val Loss: 1.2995 | Val Acc: 0.4175\nEpoch 060 | Train Loss: 1.1491 | Train Acc: 0.4867 | Val Loss: 1.2973 | Val Acc: 0.4104\nEpoch 061 | Train Loss: 1.1549 | Train Acc: 0.4897 | Val Loss: 1.2938 | Val Acc: 0.4104\nEpoch 062 | Train Loss: 1.1393 | Train Acc: 0.4867 | Val Loss: 1.2967 | Val Acc: 0.3986\nEpoch 063 | Train Loss: 1.1455 | Train Acc: 0.4956 | Val Loss: 1.3041 | Val Acc: 0.4175\nEpoch 064 | Train Loss: 1.1470 | Train Acc: 0.4843 | Val Loss: 1.2952 | Val Acc: 0.4245\nEpoch 065 | Train Loss: 1.1526 | Train Acc: 0.4885 | Val Loss: 1.2896 | Val Acc: 0.4104\nEpoch 066 | Train Loss: 1.1417 | Train Acc: 0.4973 | Val Loss: 1.2971 | Val Acc: 0.4245\nEpoch 067 | Train Loss: 1.1545 | Train Acc: 0.4820 | Val Loss: 1.2764 | Val Acc: 0.4033\nEpoch 068 | Train Loss: 1.1419 | Train Acc: 0.4903 | Val Loss: 1.2792 | Val Acc: 0.4151\nEpoch 069 | Train Loss: 1.1527 | Train Acc: 0.4903 | Val Loss: 1.2868 | Val Acc: 0.4151\nEpoch 070 | Train Loss: 1.1462 | Train Acc: 0.4914 | Val Loss: 1.2805 | Val Acc: 0.4009\nEpoch 071 | Train Loss: 1.1402 | Train Acc: 0.5080 | Val Loss: 1.2945 | Val Acc: 0.3986\nEpoch 072 | Train Loss: 1.1415 | Train Acc: 0.4956 | Val Loss: 1.2990 | Val Acc: 0.4127\nEpoch 073 | Train Loss: 1.1381 | Train Acc: 0.4991 | Val Loss: 1.2955 | Val Acc: 0.3986\nEpoch 074 | Train Loss: 1.1285 | Train Acc: 0.4897 | Val Loss: 1.2892 | Val Acc: 0.4151\nEpoch 075 | Train Loss: 1.1310 | Train Acc: 0.4944 | Val Loss: 1.2907 | Val Acc: 0.4127\nEpoch 076 | Train Loss: 1.1531 | Train Acc: 0.4767 | Val Loss: 1.2944 | Val Acc: 0.4151\nEpoch 077 | Train Loss: 1.1335 | Train Acc: 0.5015 | Val Loss: 1.2943 | Val Acc: 0.4198\nEpoch 078 | Train Loss: 1.1397 | Train Acc: 0.4849 | Val Loss: 1.2883 | Val Acc: 0.4127\nEpoch 079 | Train Loss: 1.1415 | Train Acc: 0.5009 | Val Loss: 1.2926 | Val Acc: 0.4104\nEpoch 080 | Train Loss: 1.1345 | Train Acc: 0.5003 | Val Loss: 1.2935 | Val Acc: 0.4127\nEpoch 081 | Train Loss: 1.1493 | Train Acc: 0.4855 | Val Loss: 1.2962 | Val Acc: 0.4033\nEpoch 082 | Train Loss: 1.1263 | Train Acc: 0.4950 | Val Loss: 1.3096 | Val Acc: 0.4057\nEpoch 083 | Train Loss: 1.1369 | Train Acc: 0.5038 | Val Loss: 1.3028 | Val Acc: 0.4175\nEpoch 084 | Train Loss: 1.1345 | Train Acc: 0.4920 | Val Loss: 1.3066 | Val Acc: 0.3939\nEpoch 085 | Train Loss: 1.1251 | Train Acc: 0.5021 | Val Loss: 1.2915 | Val Acc: 0.4269\nEpoch 086 | Train Loss: 1.1442 | Train Acc: 0.4814 | Val Loss: 1.2899 | Val Acc: 0.4198\nEpoch 087 | Train Loss: 1.1357 | Train Acc: 0.5009 | Val Loss: 1.2974 | Val Acc: 0.4104\nEpoch 088 | Train Loss: 1.1338 | Train Acc: 0.4861 | Val Loss: 1.2974 | Val Acc: 0.4175\nEpoch 089 | Train Loss: 1.1321 | Train Acc: 0.5074 | Val Loss: 1.3034 | Val Acc: 0.4127\nEpoch 090 | Train Loss: 1.1282 | Train Acc: 0.4891 | Val Loss: 1.3122 | Val Acc: 0.4316\nEpoch 091 | Train Loss: 1.1335 | Train Acc: 0.5038 | Val Loss: 1.3192 | Val Acc: 0.4104\nEpoch 092 | Train Loss: 1.1208 | Train Acc: 0.5050 | Val Loss: 1.3099 | Val Acc: 0.4245\nEpoch 093 | Train Loss: 1.1105 | Train Acc: 0.5281 | Val Loss: 1.3032 | Val Acc: 0.4222\nEpoch 094 | Train Loss: 1.1301 | Train Acc: 0.4979 | Val Loss: 1.3020 | Val Acc: 0.4269\nEpoch 095 | Train Loss: 1.1230 | Train Acc: 0.5015 | Val Loss: 1.3052 | Val Acc: 0.4127\nEpoch 096 | Train Loss: 1.1191 | Train Acc: 0.4979 | Val Loss: 1.3032 | Val Acc: 0.4057\nEpoch 097 | Train Loss: 1.1058 | Train Acc: 0.5381 | Val Loss: 1.3115 | Val Acc: 0.4151\nEpoch 098 | Train Loss: 1.1141 | Train Acc: 0.5086 | Val Loss: 1.3000 | Val Acc: 0.4316\nEpoch 099 | Train Loss: 1.1235 | Train Acc: 0.5068 | Val Loss: 1.2935 | Val Acc: 0.4151\nEpoch 100 | Train Loss: 1.1138 | Train Acc: 0.5062 | Val Loss: 1.2997 | Val Acc: 0.4222\nEpoch 101 | Train Loss: 1.1109 | Train Acc: 0.5038 | Val Loss: 1.2971 | Val Acc: 0.4104\nEpoch 102 | Train Loss: 1.1084 | Train Acc: 0.5192 | Val Loss: 1.2926 | Val Acc: 0.4222\nEpoch 103 | Train Loss: 1.1268 | Train Acc: 0.5133 | Val Loss: 1.2950 | Val Acc: 0.4175\nEpoch 104 | Train Loss: 1.1153 | Train Acc: 0.5086 | Val Loss: 1.2819 | Val Acc: 0.4198\nEpoch 105 | Train Loss: 1.1205 | Train Acc: 0.5168 | Val Loss: 1.2978 | Val Acc: 0.4009\nEpoch 106 | Train Loss: 1.1303 | Train Acc: 0.5003 | Val Loss: 1.3003 | Val Acc: 0.4340\nEpoch 107 | Train Loss: 1.1131 | Train Acc: 0.4991 | Val Loss: 1.2940 | Val Acc: 0.4363\nEpoch 108 | Train Loss: 1.1160 | Train Acc: 0.5151 | Val Loss: 1.2951 | Val Acc: 0.4104\nEpoch 109 | Train Loss: 1.1115 | Train Acc: 0.5239 | Val Loss: 1.3073 | Val Acc: 0.4222\nEpoch 110 | Train Loss: 1.1205 | Train Acc: 0.5080 | Val Loss: 1.2952 | Val Acc: 0.4151\nEpoch 111 | Train Loss: 1.1063 | Train Acc: 0.5056 | Val Loss: 1.2895 | Val Acc: 0.4151\nEpoch 112 | Train Loss: 1.0972 | Train Acc: 0.5080 | Val Loss: 1.2889 | Val Acc: 0.4269\nEpoch 113 | Train Loss: 1.1134 | Train Acc: 0.5145 | Val Loss: 1.3009 | Val Acc: 0.4363\nEpoch 114 | Train Loss: 1.1225 | Train Acc: 0.5062 | Val Loss: 1.3070 | Val Acc: 0.4175\nEpoch 115 | Train Loss: 1.1057 | Train Acc: 0.5162 | Val Loss: 1.3104 | Val Acc: 0.4151\nEpoch 116 | Train Loss: 1.0871 | Train Acc: 0.5168 | Val Loss: 1.2991 | Val Acc: 0.4104\nEpoch 117 | Train Loss: 1.1037 | Train Acc: 0.5204 | Val Loss: 1.3039 | Val Acc: 0.4104\nEpoch 118 | Train Loss: 1.0973 | Train Acc: 0.5115 | Val Loss: 1.3059 | Val Acc: 0.4033\nEpoch 119 | Train Loss: 1.1051 | Train Acc: 0.5145 | Val Loss: 1.3065 | Val Acc: 0.4222\nEpoch 120 | Train Loss: 1.1082 | Train Acc: 0.5180 | Val Loss: 1.3042 | Val Acc: 0.4245\nEpoch 121 | Train Loss: 1.0951 | Train Acc: 0.5162 | Val Loss: 1.2997 | Val Acc: 0.4151\nEpoch 122 | Train Loss: 1.1059 | Train Acc: 0.5139 | Val Loss: 1.3068 | Val Acc: 0.4057\nEpoch 123 | Train Loss: 1.0931 | Train Acc: 0.5192 | Val Loss: 1.3098 | Val Acc: 0.4292\nEpoch 124 | Train Loss: 1.0948 | Train Acc: 0.5210 | Val Loss: 1.3020 | Val Acc: 0.4080\nEpoch 125 | Train Loss: 1.1003 | Train Acc: 0.5145 | Val Loss: 1.2877 | Val Acc: 0.4151\nEpoch 126 | Train Loss: 1.1022 | Train Acc: 0.5103 | Val Loss: 1.2900 | Val Acc: 0.4198\nEpoch 127 | Train Loss: 1.0929 | Train Acc: 0.5092 | Val Loss: 1.3005 | Val Acc: 0.4222\nEpoch 128 | Train Loss: 1.0840 | Train Acc: 0.5286 | Val Loss: 1.2987 | Val Acc: 0.4363\nEpoch 129 | Train Loss: 1.0790 | Train Acc: 0.5263 | Val Loss: 1.3137 | Val Acc: 0.4080\nEpoch 130 | Train Loss: 1.1001 | Train Acc: 0.5180 | Val Loss: 1.3043 | Val Acc: 0.4340\nEpoch 131 | Train Loss: 1.0934 | Train Acc: 0.5210 | Val Loss: 1.2936 | Val Acc: 0.4175\nEpoch 132 | Train Loss: 1.0969 | Train Acc: 0.5239 | Val Loss: 1.3030 | Val Acc: 0.4104\nEpoch 133 | Train Loss: 1.0854 | Train Acc: 0.5298 | Val Loss: 1.3002 | Val Acc: 0.4222\nEpoch 134 | Train Loss: 1.0853 | Train Acc: 0.5245 | Val Loss: 1.3102 | Val Acc: 0.4151\nEpoch 135 | Train Loss: 1.1001 | Train Acc: 0.5015 | Val Loss: 1.3151 | Val Acc: 0.3962\nEpoch 136 | Train Loss: 1.0869 | Train Acc: 0.5263 | Val Loss: 1.3203 | Val Acc: 0.4009\nEpoch 137 | Train Loss: 1.1005 | Train Acc: 0.5109 | Val Loss: 1.3235 | Val Acc: 0.3939\nEpoch 138 | Train Loss: 1.0832 | Train Acc: 0.5269 | Val Loss: 1.3057 | Val Acc: 0.4222\nEpoch 139 | Train Loss: 1.0938 | Train Acc: 0.5310 | Val Loss: 1.3128 | Val Acc: 0.4080\nEpoch 140 | Train Loss: 1.0810 | Train Acc: 0.5322 | Val Loss: 1.3245 | Val Acc: 0.4198\nEpoch 141 | Train Loss: 1.0835 | Train Acc: 0.5239 | Val Loss: 1.3151 | Val Acc: 0.4245\nEpoch 142 | Train Loss: 1.0866 | Train Acc: 0.5322 | Val Loss: 1.3223 | Val Acc: 0.4245\nEpoch 143 | Train Loss: 1.1038 | Train Acc: 0.5127 | Val Loss: 1.3171 | Val Acc: 0.4104\nEpoch 144 | Train Loss: 1.0892 | Train Acc: 0.5292 | Val Loss: 1.3160 | Val Acc: 0.4222\nEpoch 145 | Train Loss: 1.0924 | Train Acc: 0.5251 | Val Loss: 1.3299 | Val Acc: 0.4033\nEpoch 146 | Train Loss: 1.0827 | Train Acc: 0.5257 | Val Loss: 1.3207 | Val Acc: 0.4057\nEpoch 147 | Train Loss: 1.0835 | Train Acc: 0.5310 | Val Loss: 1.3165 | Val Acc: 0.4009\nEpoch 148 | Train Loss: 1.0815 | Train Acc: 0.5322 | Val Loss: 1.3178 | Val Acc: 0.4104\nEpoch 149 | Train Loss: 1.0639 | Train Acc: 0.5292 | Val Loss: 1.3221 | Val Acc: 0.4175\nEpoch 150 | Train Loss: 1.0726 | Train Acc: 0.5286 | Val Loss: 1.3300 | Val Acc: 0.4151\nEpoch 151 | Train Loss: 1.0764 | Train Acc: 0.5251 | Val Loss: 1.3321 | Val Acc: 0.4009\nEpoch 152 | Train Loss: 1.0835 | Train Acc: 0.5109 | Val Loss: 1.3125 | Val Acc: 0.4245\nEpoch 153 | Train Loss: 1.0952 | Train Acc: 0.5127 | Val Loss: 1.3228 | Val Acc: 0.4127\nEpoch 154 | Train Loss: 1.0821 | Train Acc: 0.5269 | Val Loss: 1.3109 | Val Acc: 0.4175\nEpoch 155 | Train Loss: 1.0623 | Train Acc: 0.5328 | Val Loss: 1.3086 | Val Acc: 0.4481\nEpoch 156 | Train Loss: 1.0922 | Train Acc: 0.5168 | Val Loss: 1.3108 | Val Acc: 0.4175\nEpoch 157 | Train Loss: 1.0751 | Train Acc: 0.5351 | Val Loss: 1.3146 | Val Acc: 0.4151\nEpoch 158 | Train Loss: 1.0811 | Train Acc: 0.5210 | Val Loss: 1.3127 | Val Acc: 0.4151\nEpoch 159 | Train Loss: 1.0727 | Train Acc: 0.5334 | Val Loss: 1.3167 | Val Acc: 0.4127\nEpoch 160 | Train Loss: 1.0703 | Train Acc: 0.5416 | Val Loss: 1.3049 | Val Acc: 0.4316\nEpoch 161 | Train Loss: 1.0631 | Train Acc: 0.5422 | Val Loss: 1.3039 | Val Acc: 0.4222\nEpoch 162 | Train Loss: 1.0780 | Train Acc: 0.5133 | Val Loss: 1.3266 | Val Acc: 0.4269\nEpoch 163 | Train Loss: 1.0727 | Train Acc: 0.5428 | Val Loss: 1.3341 | Val Acc: 0.4080\nEpoch 164 | Train Loss: 1.0632 | Train Acc: 0.5145 | Val Loss: 1.3240 | Val Acc: 0.4057\nEpoch 165 | Train Loss: 1.0720 | Train Acc: 0.5340 | Val Loss: 1.3153 | Val Acc: 0.4080\nEpoch 166 | Train Loss: 1.0711 | Train Acc: 0.5257 | Val Loss: 1.3233 | Val Acc: 0.4127\nEpoch 167 | Train Loss: 1.0728 | Train Acc: 0.5298 | Val Loss: 1.3273 | Val Acc: 0.4245\nEpoch 168 | Train Loss: 1.0592 | Train Acc: 0.5328 | Val Loss: 1.3333 | Val Acc: 0.4269\nEpoch 169 | Train Loss: 1.0751 | Train Acc: 0.5286 | Val Loss: 1.3343 | Val Acc: 0.4151\nEpoch 170 | Train Loss: 1.0605 | Train Acc: 0.5346 | Val Loss: 1.3232 | Val Acc: 0.4316\nEpoch 171 | Train Loss: 1.0674 | Train Acc: 0.5328 | Val Loss: 1.3104 | Val Acc: 0.4292\nEpoch 172 | Train Loss: 1.0553 | Train Acc: 0.5440 | Val Loss: 1.3183 | Val Acc: 0.4198\nEpoch 173 | Train Loss: 1.0556 | Train Acc: 0.5357 | Val Loss: 1.3200 | Val Acc: 0.4410\nEpoch 174 | Train Loss: 1.0731 | Train Acc: 0.5340 | Val Loss: 1.3227 | Val Acc: 0.4269\nEpoch 175 | Train Loss: 1.0485 | Train Acc: 0.5493 | Val Loss: 1.3139 | Val Acc: 0.4316\nEpoch 176 | Train Loss: 1.0548 | Train Acc: 0.5464 | Val Loss: 1.3233 | Val Acc: 0.4104\nEpoch 177 | Train Loss: 1.0532 | Train Acc: 0.5393 | Val Loss: 1.3239 | Val Acc: 0.4316\nEpoch 178 | Train Loss: 1.0645 | Train Acc: 0.5369 | Val Loss: 1.3182 | Val Acc: 0.4245\nEpoch 179 | Train Loss: 1.0486 | Train Acc: 0.5440 | Val Loss: 1.3280 | Val Acc: 0.4080\nEpoch 180 | Train Loss: 1.0652 | Train Acc: 0.5281 | Val Loss: 1.3132 | Val Acc: 0.4316\nEpoch 181 | Train Loss: 1.0658 | Train Acc: 0.5351 | Val Loss: 1.3160 | Val Acc: 0.4151\nEpoch 182 | Train Loss: 1.0506 | Train Acc: 0.5416 | Val Loss: 1.3289 | Val Acc: 0.3986\nEpoch 183 | Train Loss: 1.0607 | Train Acc: 0.5334 | Val Loss: 1.3364 | Val Acc: 0.4151\nEpoch 184 | Train Loss: 1.0698 | Train Acc: 0.5233 | Val Loss: 1.3370 | Val Acc: 0.4151\nEpoch 185 | Train Loss: 1.0540 | Train Acc: 0.5381 | Val Loss: 1.3248 | Val Acc: 0.4198\nEpoch 186 | Train Loss: 1.0511 | Train Acc: 0.5411 | Val Loss: 1.3331 | Val Acc: 0.4292\nEpoch 187 | Train Loss: 1.0466 | Train Acc: 0.5328 | Val Loss: 1.3352 | Val Acc: 0.4198\nEpoch 188 | Train Loss: 1.0712 | Train Acc: 0.5198 | Val Loss: 1.3527 | Val Acc: 0.4198\nEpoch 189 | Train Loss: 1.0581 | Train Acc: 0.5375 | Val Loss: 1.3570 | Val Acc: 0.4175\nEpoch 190 | Train Loss: 1.0601 | Train Acc: 0.5227 | Val Loss: 1.3559 | Val Acc: 0.3892\nEpoch 191 | Train Loss: 1.0660 | Train Acc: 0.5399 | Val Loss: 1.3531 | Val Acc: 0.4127\nEpoch 192 | Train Loss: 1.0361 | Train Acc: 0.5434 | Val Loss: 1.3501 | Val Acc: 0.4292\nEpoch 193 | Train Loss: 1.0504 | Train Acc: 0.5487 | Val Loss: 1.3449 | Val Acc: 0.4033\nEpoch 194 | Train Loss: 1.0602 | Train Acc: 0.5363 | Val Loss: 1.3406 | Val Acc: 0.4269\nEpoch 195 | Train Loss: 1.0586 | Train Acc: 0.5399 | Val Loss: 1.3419 | Val Acc: 0.4009\nEpoch 196 | Train Loss: 1.0479 | Train Acc: 0.5281 | Val Loss: 1.3464 | Val Acc: 0.4127\nEpoch 197 | Train Loss: 1.0544 | Train Acc: 0.5328 | Val Loss: 1.3359 | Val Acc: 0.4175\nEpoch 198 | Train Loss: 1.0582 | Train Acc: 0.5210 | Val Loss: 1.3456 | Val Acc: 0.4127\nEpoch 199 | Train Loss: 1.0336 | Train Acc: 0.5405 | Val Loss: 1.3364 | Val Acc: 0.4175\nEpoch 200 | Train Loss: 1.0485 | Train Acc: 0.5369 | Val Loss: 1.3419 | Val Acc: 0.4151\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"!pip install torch","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from lazypredict.Supervised import LazyClassifier\nfrom sklearn.model_selection import train_test_split\n\n# Split your features\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y_combined, test_size=0.2, random_state=42)\n\n# Run LazyClassifier\nclf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\nmodels, predictions = clf.fit(X_train, X_test, y_train, y_test)\n\n# Show best model\nprint(models.head())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nbest_model = RandomForestClassifier()\nbest_model.fit(aug_X_train, aug_y_train)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = best_model.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprint(f\"✅ Accuracy on test set: {acc:.4f}\")\nprint(\"\\n📊 Classification Report:\")\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\n\n# Path to dataset\nbase_path = '/kaggle/input/mtcaic3'\nselected_channels = ['OZ', 'PZ', 'CZ', 'PO8']\n\n# Load test.csv\ntest_df = pd.read_csv(os.path.join(base_path, 'test.csv'))\n\n# 🔍 Filter last 50 SSVEP entries\nssvep_df = test_df[test_df['task'] == 'SSVEP'].copy()\nssvep_df = ssvep_df.sort_values(by='id').tail(50)\n\n# Prepare predictions\nids = []\npredicted_labels = []\n\nfor _, row in ssvep_df.iterrows():\n    subject_id = row['subject_id']\n    session = row['trial_session']\n    trial = row['trial']\n    id_num = row['id']\n    task = row['task']\n\n    eeg_path = f\"{base_path}/{task}/test/{subject_id}/{session}/EEGdata.csv\"\n    \n    if not os.path.exists(eeg_path):\n        print(f\"⚠️ Missing file: {eeg_path}\")\n        continue\n\n    eeg = pd.read_csv(eeg_path)\n    samples_per_trial = 1750  # SSVEP only\n\n    start = (trial - 1) * samples_per_trial\n    end = trial * samples_per_trial\n\n    eeg_segment = eeg[selected_channels].iloc[start:end].values.T.astype(np.float32)\n    gyro_segment = eeg[['Gyro1', 'Gyro2', 'Gyro3']].iloc[start:end].values.T.astype(np.float32)\n\n    eeg_features = extract_combined_features(eeg_segment)\n    gyro_features = extract_gyro_features(gyro_segment)\n    full_features = np.concatenate([eeg_features, gyro_features])\n\n    try:\n        if 'scaler' in globals() and hasattr(scaler, 'transform') and scaler.n_features_in_ == len(full_features):\n            full_features_scaled = scaler.transform([full_features])\n            prediction = lgbm.predict(full_features_scaled)[0]\n        else:\n            prediction = lgbm.predict([full_features])[0]\n    except Exception as e:\n        print(f\" Prediction failed for id {id_num}: {e}\")\n        continue\n\n    ids.append(id_num)\n    predicted_labels.append(prediction)\n\n# Save predictions\nlabel_map = {0: 'Left', 1: 'Right', 2: 'Forward', 3: 'Backward'}  # Example\npredicted_labels = [label_map[label] for label in predicted_labels]\nsubmission = pd.DataFrame({'id': ids, 'label': predicted_labels})\nsubmission.to_csv('ssvep_last50_submission.csv', index=False)\n\nprint(\"✅ ssvep_last50_submission.csv generated successfully!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"thresholds = [2.0, 3.0, 3.5, 4, 4.5]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\n\nbest_acc = 0\nbest_threshold = None\nresults = {}\n\nfor threshold in thresholds:\n    print(f\"\\n🔍 Trying threshold: {threshold}\")\n    X_combined, y_combined = [], []\n\n    for _, row in ssvep_df.iterrows():\n        dataset_type = 'train' if row['id'] <= 4800 else 'validation'\n        eeg_path = f\"{base_path}/SSVEP/{dataset_type}/{row['subject_id']}/{row['trial_session']}/EEGdata.csv\"\n        eeg = pd.read_csv(eeg_path)\n\n        trial_num = int(row['trial'])\n        start = (trial_num - 1) * 1750\n        end = trial_num * 1750\n\n        eeg_segment = eeg[selected_channels].iloc[start:end].values.T.astype(np.float32)\n        gyro_segment = eeg[['Gyro1', 'Gyro2', 'Gyro3']].iloc[start:end].values.T.astype(np.float32)\n\n        gyro_movement = np.linalg.norm(gyro_segment.T, axis=1)\n        if np.std(gyro_movement) > threshold:\n            continue\n\n        eeg_features = extract_combined_features(eeg_segment)\n        gyro_features = extract_gyro_features(gyro_segment)\n        full_features = np.concatenate([eeg_features, gyro_features])\n\n        X_combined.append(full_features)\n        y_combined.append(row['label'])\n\n    if len(X_combined) < 10:\n        print(\"❌ Too few trials left, skipping this threshold\")\n        continue\n\n    X_combined = np.array(X_combined)\n    y_combined = np.array(y_combined)\n\n    # Train/test split\n    X_scaled = StandardScaler().fit_transform(X_combined)\n    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_combined, test_size=0.2, random_state=42)\n\n    # Train classifier\n    clf = RandomForestClassifier(random_state=42)\n    clf.fit(X_train, y_train)\n    acc = accuracy_score(y_test, clf.predict(X_test))\n\n    print(f\"✅ Accuracy at threshold {threshold}: {acc:.4f}\")\n    results[threshold] = acc\n\n    if acc > best_acc:\n        best_acc = acc\n        best_threshold = threshold\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.decomposition import PCA\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_pca, y_combined, test_size=0.2, random_state=42)\n\nfrom lazypredict.Supervised import LazyClassifier\nclf = LazyClassifier(verbose=0, ignore_warnings=True)\nmodels, predictions = clf.fit(X_train, X_test, y_train, y_test)\n\nprint(models)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}